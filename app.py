import streamlit as st
import torch
from torchvision import transforms
from PIL import Image
import io
from model import CNN
import os
import zipfile

#ãƒãƒŠãƒ¼ã®è¡¨ç¤º
st.image('banner.png', use_column_width=True)

# Streamlitã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«
st.title('CNN TruthFinderğŸ¤–')
st.write('GANã§ç”Ÿæˆã•ã‚ŒãŸç”»åƒã¨æœ¬ç‰©ã®ç”»åƒã‚’CNNã«ã‚ˆã£ã¦è­˜åˆ¥ã—ã¾ã™ã€‚')

# PNGãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ãƒªã‚¹ãƒˆã¨ã—ã¦å®šç¾©
file_paths = ['image/gan_image1.png', 'image/gan_image2.png', 'image/true_image1.png', 'image/true_image2.png']

# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã‚’å®šç¾©
zip_name = "image/test_images.zip"

# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
with zipfile.ZipFile(zip_name, 'w') as zipf:
    for file_path in file_paths:
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPã«è¿½åŠ 
        zipf.write(file_path, os.path.basename(file_path))

# ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
with open(zip_name, "rb") as file:
    st.download_button(
        label="ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=file,
        file_name=zip_name,
        mime='application/zip'
    )

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ç”»åƒã®å—ã‘å–ã‚Š
uploaded_file = st.file_uploader("ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„...", type=["png", "jpg", "jpeg"])

# ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ï¼ˆå‰ã«å®šç¾©ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹ï¼‰
model = CNN()  # ã“ã“ã§CNNã¯äº‹å‰ã«å®šç¾©ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹
model.load_state_dict(torch.load('model.pth'))  # å­¦ç¿’æ¸ˆã¿ã®é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰
model.eval()

# ç”»åƒå‰å‡¦ç†ã®é–¢æ•°
def transform_image(image):
    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=1), # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«åŒ–
        transforms.Resize((28, 28)),
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
    return transform(image).unsqueeze(0)

# ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚‰
if uploaded_file is not None:
    image = Image.open(uploaded_file)
    
    # ã‚«ãƒ©ãƒ ã®è¨­å®šï¼ˆå·¦ã‚«ãƒ©ãƒ ã€ç©ºç™½ã‚¹ãƒšãƒ¼ã‚¹ã€å³ã‚«ãƒ©ãƒ ï¼‰
    col1, col_space, col2 = st.columns([5, 1, 5])  # æ•°å€¤ã¯ç›¸å¯¾çš„ãªå¹…
    
    # å·¦å´ã®ã‚«ãƒ©ãƒ ã«ç”»åƒã‚’è¡¨ç¤º
    with col1:
        st.image(image, caption='ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ', use_column_width=True)
    
    # å³å´ã®ã‚«ãƒ©ãƒ ã«è­˜åˆ¥çµæœã‚’è¡¨ç¤º
    with col2:
        st.write("è­˜åˆ¥çµæœ...")
        
        # ç”»åƒã‚’ãƒ¢ãƒ‡ãƒ«ã«é©ç”¨ã™ã‚‹æº–å‚™
        image = transform_image(image)
        
        # æ¨è«–
        with torch.no_grad():
            outputs = model(image)
            _, predicted = torch.max(outputs.data, 1)
        
        # çµæœã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
        if predicted.item() == 0:
            st.write('GANã§ç”Ÿæˆã•ã‚ŒãŸç”»åƒã§ã™ã€‚')
        else:
            st.write('æœ¬ç‰©ã®ç”»åƒã§ã™ã€‚')
        
        # # æ¨è«–ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ã‚’è¡¨ç¤º
        # st.write(f'äºˆæ¸¬ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹: {predicted.item()}')
